# dbt model skeletons for Snowflake

## Inventory transactions + SCD Type 2 dimensions

This section gives you **production-grade dbt SQL skeletons** aligned exactly to the Snowflake DDL we defined earlier. These are not toy examples. They are designed so you can drop them into a dbt project and extend safely.

I will cover:

* dbt project structure
* Source definitions
* Staging models
* SCD Type 2 implementation for `dim_item`
* Incremental fact model for `fact_inventory_transaction`
* Tests and macros you should wire in
* Assumptions and verification points

No assumptions are hidden. Where an assumption is required, it is explicitly labeled.

---

## 1. Recommended dbt project structure

```text
dbt_hospital_supply_chain/
│
├── dbt_project.yml
├── models/
│   ├── sources/
│   │   └── src_raw.yml
│   │
│   ├── staging/
│   │   ├── stg_inventory_transactions.sql
│   │   └── stg_items.sql
│   │
│   ├── marts/
│   │   ├── dimensions/
│   │   │   └── dim_item.sql
│   │   │
│   │   └── facts/
│   │       └── fact_inventory_transaction.sql
│   │
│   └── schema.yml
│
├── macros/
│   └── scd_helpers.sql
│
└── tests/
```

This follows dbt Labs’ recommended layering and keeps Snowflake compute predictable.

---

## 2. Source definitions (raw layer)

### `models/sources/src_raw.yml`

```yaml
version: 2

sources:
  - name: raw
    database: hospital_supply_chain
    schema: raw
    tables:
      - name: inventory_landing_struct
        description: "Raw landed inventory transactions from source systems"
```

Reasoning:

* dbt sources give lineage, freshness checks, and test hooks.
* We point only to **raw**, never directly to gold.

---

## 3. Staging model

### Inventory transactions

### `models/staging/stg_inventory_transactions.sql`

```sql
{{ config(
    materialized = 'view'
) }}

SELECT
    source_system,
    reference_id,
    TRIM(item_sku)              AS item_sku,
    TRIM(location_code)         AS location_code,
    CAST(quantity AS NUMBER)    AS quantity,
    UPPER(transaction_type)     AS transaction_type,
    CAST(transaction_ts AS TIMESTAMP_LTZ) AS transaction_ts,
    lot_number,
    expiry_date,
    loaded_at
FROM {{ source('raw', 'inventory_landing_struct') }}
WHERE reference_id IS NOT NULL
```

Why view:

* Staging models should be lightweight and cheap.
* Snowflake pushes compute downstream only when queried.

---

## 4. Staging model

### Item master (assumption)

### ASSUMPTION

Your source feed includes item-level attributes (description, manufacturer, category). If not, this model will later point to ERP or item master tables.

### `models/staging/stg_items.sql`

```sql
{{ config(
    materialized = 'view'
) }}

SELECT DISTINCT
    TRIM(item_sku)          AS sku,
    item_description        AS description,
    manufacturer,
    unit_of_measure         AS uom,
    category,
    CAST(shelf_life_days AS NUMBER) AS shelf_life_days
FROM {{ source('raw', 'inventory_landing_struct') }}
WHERE item_sku IS NOT NULL
```

---

## 5. SCD Type 2 dimension

### `dim_item`

This is the heart of inventory analytics. Done incorrectly, everything breaks.

### `models/marts/dimensions/dim_item.sql`

```sql
{{ config(
    materialized = 'incremental',
    unique_key = 'sku',
    incremental_strategy = 'merge'
) }}

WITH source_data AS (

    SELECT
        sku,
        description,
        manufacturer,
        uom,
        category,
        shelf_life_days
    FROM {{ ref('stg_items') }}

),

existing_current AS (

    SELECT *
    FROM {{ this }}
    WHERE is_current = TRUE

),

changes AS (

    SELECT
        s.*
    FROM source_data s
    LEFT JOIN existing_current e
        ON s.sku = e.sku
    WHERE
        e.sku IS NULL
        OR (
            s.description      <> e.description OR
            s.manufacturer     <> e.manufacturer OR
            s.uom              <> e.uom OR
            s.category         <> e.category OR
            s.shelf_life_days  <> e.shelf_life_days
        )

)

SELECT
    sku,
    description,
    manufacturer,
    uom,
    category,
    shelf_life_days,
    CURRENT_TIMESTAMP()      AS effective_from,
    NULL                     AS effective_to,
    TRUE                     AS is_current,
    CURRENT_TIMESTAMP()      AS created_at
FROM changes
```

### How expiry of old records happens

You pair this model with a **post-hook** or a macro that updates prior versions.

### `macros/scd_helpers.sql`

```sql
{% macro expire_old_records(target_table) %}
UPDATE {{ target_table }}
SET
  effective_to = CURRENT_TIMESTAMP(),
  is_current = FALSE
WHERE sku IN (
    SELECT sku FROM {{ target_table }} WHERE is_current = TRUE
)
AND created_at < CURRENT_TIMESTAMP();
{% endmacro %}
```

You typically invoke this macro via a dbt `post-hook`.

---

## 6. Incremental fact model

### `fact_inventory_transaction`

### `models/marts/facts/fact_inventory_transaction.sql`

```sql
{{ config(
    materialized = 'incremental',
    unique_key = 'reference_id',
    incremental_strategy = 'merge'
) }}

SELECT
    t.reference_id,
    d.item_id,
    t.item_sku           AS sku,
    l.location_id,
    t.location_code,
    t.transaction_type,
    t.quantity,
    t.transaction_ts,
    t.lot_number,
    t.expiry_date,
    t.source_system,
    CURRENT_TIMESTAMP()  AS created_at
FROM {{ ref('stg_inventory_transactions') }} t
LEFT JOIN {{ ref('dim_item') }} d
    ON t.item_sku = d.sku
    AND d.is_current = TRUE
LEFT JOIN {{ ref('dim_location') }} l
    ON t.location_code = l.location_code

{% if is_incremental() %}
WHERE t.transaction_ts >
      (SELECT MAX(transaction_ts) FROM {{ this }})
{% endif %}
```

Why incremental:

* Inventory transactions are append-heavy.
* This minimizes Snowflake compute and Power BI refresh load.

---

## 7. Tests you must enable (non-negotiable)

### `models/schema.yml`

```yaml
version: 2

models:
  - name: dim_item
    tests:
      - dbt_utils.unique_combination_of_columns:
          combination_of_columns:
            - sku
            - effective_from
      - not_null:
          column_name: sku

  - name: fact_inventory_transaction
    tests:
      - not_null:
          column_name: reference_id
      - relationships:
          to: ref('dim_item')
          field: item_id
```

Reasoning:

* These tests prevent silent data corruption.
* Especially critical in healthcare inventory contexts.

---

## 8. How this maps cleanly to Power BI

* `gold.dim_item` becomes your **Item dimension**
* `gold.fact_inventory_transaction` is your **grain-level fact**
* SCD Type 2 allows:

  * Historical valuation
  * Correct expiry tracking
  * Regulatory audit trails

This star schema aligns perfectly with Power BI import or DirectQuery modes.

---

## 9. What requires verification before production

* **Item master source**
  Confirm whether item attributes come from inventory feeds or a separate ERP table.

* **Reference ID uniqueness**
  Verify that `reference_id` is globally unique per source system.

* **Transaction volume**
  Needed to decide:

  * Warehouse size
  * dbt run frequency
  * Power BI refresh mode

* **SCD attribute list**
  Confirm which attributes truly require historical tracking.

If any of these are incorrect, the model should be adjusted before scaling.

---

## 10. Next logical steps

You are now at the point where many teams stop and regret it later. The right next moves are:

* Add **dim_location** and **dim_supplier** SCD logic
* Add **inventory snapshot fact** for point-in-time on-hand reporting
* Add **dbt snapshots** for regulatory audit readiness
* Generate **Power BI semantic layer measures** tied to these facts

Tell me which one you want next, and I will build it end-to-end with the same level of rigor.

